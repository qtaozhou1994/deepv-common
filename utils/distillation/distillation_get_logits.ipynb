{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "caffe_root = '/opt/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "model_def = './deploy_8inceptionv2_voting.prototxt' #模型定义\n",
    "model_weights = './8_inceptionv2_ave.caffemodel'  #模型参数\n",
    "mean = [117, 117, 117] #模型训练时的mean\n",
    "sacle = 0.0078125 #模型训练时的scale\n",
    "height = 224 #模型输入图片高度\n",
    "width = 224 #模型输入宽度\n",
    "store_size = 1000 #保存的batch大小\n",
    "label_size = 17 #label长度\n",
    "teacher_logits_size = 61 #模型输出的长度\n",
    "output_layer_name = 'teacher_logits' #模型输出层名字\n",
    "filename = './train.txt' #训练集文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载teacher model\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          3,         # 3-channel (RGB) images\n",
    "                          height, width)  # image size is 224 x 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caffe 图片的预处理\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "mu = np.array(mean)\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_mean('data', mu)\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读训练集\n",
    "\n",
    "with open(filename) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "lines = [x.strip().split() for x in content]\n",
    "tail_len = len(lines) % store_size\n",
    "total_h5_file_size =len(lines) / store_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历训练集，保存需要的teacher模型输出，以及原图片（可选）\n",
    "\n",
    "import h5py, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "filename = './train.txt'\n",
    "with open(filename) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "lines = [x.strip().split() for x in content]\n",
    "\n",
    "# If you do not have enough memory split data into\n",
    "# multiple batches and generate multiple separate h5 files\n",
    "image = np.zeros((store_size, 3, height, width), dtype='f4' )\n",
    "teacher_logits = np.zeros((store_size, teacher_logits_size), dtype='f4' )\n",
    "ground_truth = np.zeros((store_size, label_size), dtype='f4' )\n",
    "for i,l in enumerate(lines):\n",
    "    if i > 0 and i % store_size == 0:\n",
    "        print i/store_size\n",
    "        with h5py.File('./distilled_data/train_' + str(i/store_size) + '.h5','w') as H:\n",
    "            H.create_dataset('image', data=image) # note the name X given to the dataset!\n",
    "            H.create_dataset('teacher_logits', data=teacher_logits) # note the name y given to the dataset!\n",
    "            H.create_dataset('ground_truth', data=ground_truth) # also save the ground truth\n",
    "            print 'train_glass_' + str(i/store_size) + '.h5'\n",
    "    img = caffe.io.load_image(l[0])\n",
    "    ground_truth[i%store_size] = l[1:]\n",
    "    img = transformer.preprocess('data', img) * scale\n",
    "    image[i%store_size] = img\n",
    "    net.blobs['data'].data[...] = img\n",
    "    output = net.forward()\n",
    "    output_logits = output[output_layer_name][0]\n",
    "    teacher_logits[i%store_size] = output_logits\n",
    "\n",
    "#处理tail部分\n",
    "tail_teacher_logits = teacher_logits[:tail_len]\n",
    "tail_ground_truth = ground_truth[:tail_len]\n",
    "tail_images = image[:tail_len]\n",
    "\n",
    "with h5py.File('./distilled_data/train_' + total_h5_file_size + '.h5','w') as H:\n",
    "    H.create_dataset('image', data=tail_images) # note the name X given to the dataset!\n",
    "    H.create_dataset('teacher_logits', data=tail_teacher_logits) # note the name y given to the dataset!\n",
    "    H.create_dataset('ground_truth', data=tail_ground_truth) # also save the ground truth\n",
    "    \n",
    "# 写一个h5的list文件，方便caffe训练时读入\n",
    "with open('./distilled_data/train_h5_list.txt','w') as L:\n",
    "    for i in range(1, total_h5_file_size+1):\n",
    "        L.write( '/train/execute/distillation/distilled_data/train_' + str(i) + '.h5' + '\\n' ) # list all h5 files you are going to use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
